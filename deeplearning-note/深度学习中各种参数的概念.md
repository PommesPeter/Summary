## 前言
对于刚刚接触深度学习的的童鞋来说，对学习率只有一个很基础的认知，当学习率过大的时候会导致模型难以收敛，过小的时候会收敛速度过慢，其实学习率是一个十分重要的参数，合理的学习率才能让模型收敛到最小点而非局部最优点或鞍点。本文后续内容将会给大家简单回顾下什么是学习率，并介绍如何科学的设置学习率。

## 什么是学习率
首先我们简单回顾下什么是学习率，在梯度下降的过程中更新权重时的超参数，即下面公式中的

$$θ=θ−α\frac{∂}{∂θ}J(θ)$$

**学习率越低，损失函数的变化速度就越慢，容易过拟合。**虽然使用低学习率可以确保我们不会错过任何局部极小值，但也意味着我们将花费更长的时间来进行收敛，特别是在被困在局部最优点的时候。而学习率过高容易发生梯度爆炸，loss振动幅度较大，模型难以收敛。下图是不同学习率的loss变化，因此，选择一个合适的学习率是十分重要的。

![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic1.jpg)

## 如何设置初始学习率
通常来说，**初始学习率以 0.01 ~ 0.001 为宜**，但这也只是经验之谈，这里为大家介绍一种较为科学的设置方法。该方法是Leslie N. Smith 在2015年的一篇论文**Cyclical Learning Rates for Training Neural Networks**中的3.3节提出来的一个非常棒的方法来找初始学习率。该方法很简单，**首先设置一个十分小的学习率，在每个epoch之后增大学习率，并记录好每个epoch的loss或者acc，迭代的epoch越多，那被检验的学习率就越多，最后将不同学习率对应的loss或acc进行对比。**
![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic9.jpg)
![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic2.jpg)

上图是论文中的实验结果，最小学习率是0，最大学习率是0.02，在大概0.01的位置，模型一开始就收敛的很好，因此可以把初始学习率选择为0.01。

![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic3.jpg)

再看下网上找到的另外一张图，从上图可以看到，当学习率从小到大变化的工程中，模型的loss在逐渐减小，但是速度慢，达到某个位置后又会急剧增大，这也对应了我们开头说的学习率小收敛慢，学习率大难以收敛。在这个图中可以很明显的选择一个合适的初始学习率0.1。

要注意一点，选择学习的时候，是从小到大，因为当学习率小的时候对loss影响不会很大，并且学习率比上一轮大，可以看做是在原始数据进行更新，如果一开始学习率很大对loss影响是很大的，这个时候再来选择初始学习率那就是无稽之谈了。

## 学习率衰减

通常在训练一定epoch之后，都会对学习率进行衰减，从而让模型收敛得更好。学习率衰减有以下三种方式：
![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic10.jpg)
轮数衰减：每经过n个epochs后学习率减半
指数衰减：每经过n个epochs后学习率乘以一个衰减率 $α_t=0.95^{epoch}α_{t−1}$
分数衰减：和指数衰减类似，不过公式不太一样 $α_t=\frac{α_{t−1}}{1+delay_rate∗epoch}$
学习率衰减的缺点
虽然采用学习率衰减的方法能让模型收敛的更好，但是如果遇到鞍点的时候，模型就没法继续收敛，如下图所示，黑点即是鞍点，如果学习率此时很小，那将永远无法走出鞍点。

![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic4.jpg)

## Cyclical Learning Rates(CRL)

那么怎么解决这个鞍点的问题，这叫要回到我们上文说到过的论文中了，这篇论文的主要内容其实就是介绍了一种方法，能在遇到鞍点时尽快从中走出去，该方法称为Cyclical Learning Rates，其思想如下，首先论文中提出了两个参数，base_lr和max_lr，我们继续以之前的图讲解，



在0.005的位置，开始出现了acc的负增长之后并趋于平缓，这个点即可作为max_lr，base_lr通常是设置为max_lr的1/3或1/4，因此0.001可以作为base_lr。

接下来就根据这两个参数进行实时的学习率的计算，论文中提到了三种更新学习率的方法：

- triangular

![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic5.jpg)

- triangular2

![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic6.jpg)

- exp range

  ![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic7.jpg)

  

  从图中可以看到，第一种方法只是在最大学习率与最小学习率中进行选择，第二种和第三种方法会对max_lr进行衰减。

三种计算方法其实都不复杂且效率很高，计算公式如下

```python
cycle = np.floor(1+iterations/(2*step_size))
x = np.abs(iterations/step_size - 2*cycle + 1)
lr= base_lr + (max_lr-base_lr)*np.maximum(0, (1-x))*scale_fn(x)
```




其中`iterations`表示的是当前迭代的步数，注意不是`epochs`，`step_size`表示的是每隔多少步数进行一次学习率的调整，这个值通常是每个epoch的步数`steps`的2-10倍，例如每个`epoch`是500步，那`step_siz`e可以选择2000，三种方法的不同之处就在于`scale_fn`：

- triangular $scale\_fn=1$

- triangular2 $scale\_fn=\frac{1}{2^{(cycle−1)}}$

- exp range $scale\_fn=γ^{steps}$

  ![](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic8.jpg)

  下图是CLR和其他情况的对比，可以看到CLR的收敛速度明显优于其他方法，而其中的acc的波动也是因为学习率变大引起的，但是对最终的结果并没有影响。

参考文献
[Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)



## 目标检测中一些参数的概念

- [学习前言](https://blog.csdn.net/weixin_44791964/article/details/104695264#_2)

- [GITHUB代码下载](https://blog.csdn.net/weixin_44791964/article/details/104695264#GITHUB_5)

- [知识储备](https://blog.csdn.net/weixin_44791964/article/details/104695264#_10)

- - [1、IOU的概念](https://blog.csdn.net/weixin_44791964/article/details/104695264#1IOU_11)
  - [2、TP TN FP FN的概念](https://blog.csdn.net/weixin_44791964/article/details/104695264#2TP_TN_FP_FN_23)
  - [3、precision（精确度）和recall（召回率）](https://blog.csdn.net/weixin_44791964/article/details/104695264#3precisionrecall_40)
  - [4、概念举例](https://blog.csdn.net/weixin_44791964/article/details/104695264#4_50)
  - [5、单个指标的局限性](https://blog.csdn.net/weixin_44791964/article/details/104695264#5_62)

- [什么是AP](https://blog.csdn.net/weixin_44791964/article/details/104695264#AP_86)

- [绘制mAP](https://blog.csdn.net/weixin_44791964/article/details/104695264#mAP_96)

# GITHUB代码下载

这个是用来绘制mAP曲线的。
https://github.com/Cartucho/mAP
这个是用来获取绘制mAP曲线所需的txt的
https://github.com/bubbliiiing/count-mAP-txt

# 知识储备

## 1、IOU的概念

IOU的概念应该比较简单，就是衡量预测框和真实框的重合程度。
下图是一个示例：图中绿色框为实际框（好像不是很绿……），红色框为预测框，当我们需要判断两个框之间的关系时，主要就是判断两个框的重合程度。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic11.jpg)
计算IOU的公式为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008205346976.png#pic_center)
可以看到IOU是一个比值，即交并比。
在分子部分，值为预测框和实际框之间的重叠区域；
在分母部分，值为预测框和实际框所占有的总区域。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic12.jpg)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191008205829350.jpg#pic_center)
交区域和并区域的比值，就是IOU。

## 2、TP TN FP FN的概念

TP TN FP FN里面一共出现了4个字母，分别是T F P N。
T是True；
F是False；
P是Positive；
N是Negative。

T或者F代表的是该样本 是否被正确分类。
P或者N代表的是该样本 原本是正样本还是负样本。

TP（True Positives）意思就是被分为了正样本，而且分对了。
TN（True Negatives）意思就是被分为了负样本，而且分对了，
FP（False Positives）意思就是被分为了正样本，但是分错了（事实上这个样本是负样本）。
FN（False Negatives）意思就是被分为了负样本，但是分错了（事实上这个样本是这样本）。

在mAP计算的过程中主要用到了，TP、FP、FN这三个概念。

## 3、precision（精确度）和recall（召回率）

$$Precision= \frac{TP}{TP+FP}$$
TP是**分类器认为是正样本而且确实是正样本的例子**，FP是**分类器认为是正样本但实际上不是正样本的例子**，Precision翻译成中文就是“**分类器认为是正类并且确实是正类的部分占所有分类器认为是正类的比例**”。

$$Recall= \frac{TP}{TP+FN}$$
TP是**分类器认为是正样本而且确实是正样本的例子**，FN是**分类器认为是负样本但实际上不是负样本的例子**，Recall翻译成中文就是“**分类器认为是正类并且确实是正类的部分占所有确实是正类的比例**”。



## 4、概念举例

![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic13.jpg)
如图所示，**蓝色的框是 真实框**。**绿色和红色的框是 预测框**，绿色的框是正样本，红色的框是负样本。一般来讲，当预测框和真实框IOU>=0.5时，被认为是正样本。
因此对于这幅图来讲。
真实框一共有3个，正样本一共有2个，负样本一共有2个。
此时
Precision=22+2=1/2Precision= \frac{2}{2+2} = 1/2*P**r**e**c**i**s**i**o**n*=2+22​=1/2
Recall=22+1=2/3Recall= \frac{2}{2+1} = 2/3*R**e**c**a**l**l*=2+12​=2/3

## 5、单个指标的局限性

在目标检测算法里面有一个非常重要的概念是置信度，如果置信度设置的高的话，预测的结果和实际情况就很符合，如果置信度低的话，就会有很多误检测。

假设一幅图里面总共有3个正样本，目标检测对这幅图的预测结果有10个，其中3个实际上是正样本，7个实际上是负样本。对应置信度如下。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic14.jpg)
如果我们将可以接受的置信度设置为0.95的话，那么目标检测算法就会将序号为1的样本作为正样本，其它的都是负样本。此时TP = 1，FP = 0，FN = 2。
$$Precision= \frac{1}{1+0}=1$$
$$Recall= \frac{1}{1+2} = \frac{1}{3}$$
此时Precision非常高，但是事实上我们只检测出一个正样本，还有两个没有检测出来，因此只用Precision就不合适。

这个时候如果我们将可以接受的置信度设置为0.35的话，那么目标检测算法就会将序号为1的样本作为正样本，其它的都是负样本。此时TP = 3，FP = 3，FN = 0。
$$Precision= \frac{3}{3+3} = \frac{1}{2}$$
$$Recall= \frac{3}{3+0} = 1$$
此时Recall非常高，但是事实上目标检测算法认为是正样本的样本里面，有3个样本确实是正样本，但有三个是负样本，存在非常严重的误检测，因此只用Recall就不合适。

二者进行结合才是评价的正确方法。

# 什么是AP

AP事实上指的是，利用不同的Precision和Recall的点的组合，画出来的曲线下面的面积。
如下面这幅图所示。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic15.jpg)
当我们取不同的置信度，可以获得不同的Precision和不同的Recall，当我们取得置信度够密集的时候，就可以获得非常多的Precision和Recall。

**此时Precision和Recall可以在图片上画出一条线，这条线下部分的面积就是某个类的AP值。**

**mAP就是所有的类的AP值求平均。**

# 绘制mAP

我们首先在这个github上下载绘制mAP所需的代码。
https://github.com/Cartucho/mAP
在这个代码中，如果想要绘制mAP则需要三个内容。分别是：
detection-results：指的是预测结果的txt。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic16.jpg)
ground-truth：指的是真实框的txt。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic17.jpg)
image-optional：指的是图片，有这个可以可视化，但是这个可以没有。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic18.jpg)
我们需要生成这三个内容，此时下载第二个库，这个是我拿我制作的ssd代码写的一个可以生成对应txt的例子。
https://github.com/bubbliiiing/count-mAP-txt
我们首先将整个VOC的数据集放到VOCdevikit中
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic19.jpg)
然后修改voc2ssd.py里面的trainval_percent，一般用数据集的10%或者更少用于测试。**如果大家放进VOCdevikit的数据集不是全部数据，而是已经筛选好的测试数据集的话，那么就把trainval_percent设置成0，表示全部的数据都用于测试。**
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic20.jpg)
然后运行voc2ssd.py。
此时会生成test.txt，存放用于测试的图片的名字。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic21.jpg)
**然后依次运行主目录下的get_dr_txt.py和get_gt_txt.py获得预测框对应的txt和真实框对应的txt。**
get_dr_txt.py是用来检测测试集里面的图片的，然后会生成每一个图片的检测结果，我重写了detect_image代码，用于生成预测框的txt。
利用for循环检测所有的图片。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic22.jpg)
get_dr_txt.py是用来获取测试集中的xml，然后根据每个xml的结果生成真实框的txt。
利用for循环检测所有的xml。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic23.jpg)
完成后我们会在input获得三个文件夹。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic24.jpg)
**此时把input内部的文件夹复制到mAP的代码中的input文件夹内部就可以了**，然后我们运行mAP的代码中的main.py，运行结束后，会生成mAP相关的文件。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic25.jpg)
结果生成在Result里面。
![在这里插入图片描述](E:\Programing Project\Git\Summary\deeplearning-note\imgs\pic26.jpg)





## 机器学习中正负样本的概念

- 所谓正样本（positive samples）、负样本（negative samples），对于某一环境下的人脸识别应用来说，比如教室中学生的人脸识别，则教室的墙壁，窗户，身体，衣服等等便属于负样本的范畴。
- 负样本通过采集的方式获取，也可通过生成的方式自动获取：
  - 工作 20x20 大小的人脸检测，为了获取尽可能多的负样本，拍摄一张 1000x1000 像素大小的车的图像，将其拆分为 20x20 大小的片段，⇒ 50x50
    - 也可将 1000x1000 ⇒ 拆分为 10x10 大小，100x100 副负样本图像，为了保持大小的一致，还需进一步将其拉伸到 20x20 的大小；

其实也就是正样本是我们需要检测、是属于图像的主体的部分，而负样本则是衬托在正样本上的物体，相当于是图像中次要的部分。不是主要的，一般来说都是一些背景之类的。看我们自己所需要检测的物体来区分正负样本


## 1. 训练集负样本继续抽样

- 保留全部正样本，负样本随机抽取一定比例加入训练集；

## 2. 数据平衡

- cascade learning 以及重采样的方法 ==> 实现数据平衡；