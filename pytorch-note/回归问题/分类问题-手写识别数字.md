# 分类问题



## 图像表示

- 每一张手写数字的图片在MNIST中图片大小是**28×28的单通道图片**

- 我们可以把这个图片==打平==成一个$长度为784$的数组，也就是**忽略它的二维之间的相关性。**

- 然后在前面插入一个维度就变成了一个$[1,784]$的一个矩阵。

单个线性模型无法解决这个问题，所以目前使用三个线性模型进行嵌套

$X=[v_1,v_2,...,v_{784}]$

- $x:[1,784]$

$H_1=XW_1+b_1$

- 为了满足矩阵相乘，相乘过程:$[1,784]×[784,d_1]+[d_1]$-->$[1,d_1]+[d_1]$ -->$[1,d_1]$
- $W_1:[d_1,784]$  $W_1^T:[784,d_1]$  $b_1:[d_1]$
- $H_1$的维度就是：$[1,d_1]$

$H_2=H_1W_2+b_2$

- 相乘过程:$[1,d_1]×[d_1,d_2] + [d_2]$-->$[1,d_2]+[d_2]$-->$[1,d_2]$
- $W_2:[d_2,d_1]$ $W_2^T:[d_1,d_2]$  $b_2:[d_2]$
- $H_2$的维度就是：$[1,d_2]$

$H_3=H_2W_3+b_3$

- 相乘过程:$[1,d_2]×[d_2,d_3]+[ d_3]$-->$[1,d_3]$
- $W_3:[d_3,d_2]$  $W_3^T:[d_2,d_3]$  $b_3:[d_3]$
- $H_3$的维度是：$[1,d_3]$

>  也就是可以理解为通过不断地矩阵乘法，改变图像的维度，最后将需要的特征输出出来。



最后输出的$H_3$中第一个维度表示图片的数量，第二个维度表示$0-9$对应的那个数字

## loss求解

**图像分类最后得到的结果是一个以独热编码的一个矩阵，然后通过对该矩阵进行解码就可以得到对应分类的类别了。**

> #### 独热编码（One-Hot Encoding）
>
> 为样本特征的每个值建立一个由一个1和若干个0组成的序列，用该序列对所有的特征值进行编码。
>
> ```
> 两个数   三个数	四个数
> 1		3		2
> 7		5		4
> 1		8		6  
> 7		3		9
> 为每一个数字进行独热编码：
> 1-10    3-100	2-1000
> 7-01    5-010   4-0100
>         8-001   6-0010
>                 9-0001
> 编码完毕后得到最终经过独热编码后的样本矩阵：
> 101001000
> 010100100
> 100010010
> 011000001
> 
> 使用场景： 计算相似度
> 
> 战狼2,    吴京,  吴京,       动作|战争|爱国
> 我不是药神,徐峥,  徐峥|王传君, 喜剧|剧情|社会
> 战狼,     吴京,  吴京,       动作|战争
> 
> 战狼2,    01    001    111000
> 我不是药神,10    110    000111
> 战狼,     01    001    110000
> ```

比如：一个是1的一个图像，被展成一个$1×10$的矩阵（这里的10是取决于有多少类别）

- e.g: 1 =>[0,1,0,0,0,0,0,0,0,0]

- e.g: 2 =>[0,0,0,3,0,0,0,0,0,0]

使用这样的编码就不会在数字之间彼此产生关系，就不会出现大小关系了。就非常适合你表达哪一类的属性。

那么，我们要比较他们之间的差距通常就是对两个矩阵做差再平方（欧氏距离算法）公式为：

$loss = (H_{3pred}-Y_{real})^2$



根据上面的公式我们得到预测的结果的公式就为：

$pred = W_3 * \{W_2[W_1+b_1]+b_2\}+b_3$

## 非线性模型

但上面的都是基于线性进行计算和检测的，但生活中遇到的很多东西都是非线性的，所以我们需要让模型具有非线性的表达能力。（我们人脑也是如此）



我们根据生物的神经元，神经元有多个输入，输出只有一个，但会有一个阈值，会让数字不会很大，过大会处于一个饱和的状态，过小就会趋近于0（sigmoid）。而在我们人工的神经网络之中x通常使用的是ReLU函数。



ReLU函数特性：梯度容易计算，只存在0和x的部分很好地避免了梯度弥散。

![image-20200601181617781](E:\Programing Project\Git\Summary\pytorch-note\回归问题\imgs\3.png)

我们就可以通过使用ReLU函数对$H_1$进行一个==非线性化==。公式如下：

$H_1=ReLU(XW_1+b_1)$

$H_2=ReLU(H_1W_2+b_2)$

$H_3=ReLU(H_2W_3+b_3)$

进行这样的操作之后再进行迭代嵌套。

$pred = W_3 * \{W_2[W_1X+b_1]+b_2\}+b_3$



## 预测

输入一个新的$X$然后进行$pred = W_3 * \{W_2[W_1X+b_1]+b_2\}+b_3$（每次线性运算都进行一次激活函数）的公式运算，最后得到的矩阵是一个$[10，1]$的一个矩阵表示为:

$$\begin{bmatrix}0.1\\0.8\\0.01\\...\end{bmatrix}$$

$P(0|x)=0.1 \\P(1|x)=0.8 \\ ...$

其中每一个元素都对应了0-9这10个数字的概率，然后我们在找到在==这个矩阵里面最大的那个元素==对应的数字就知道了这个识别的结果是啥。



## 实战

为什么经过三次线性运算就可以达到分类的效果？